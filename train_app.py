import streamlit as st
import pandas as pd
import xgboost as xgb
from sklearn.metrics import accuracy_score
import os
import pickle
from utils import (
    load_processed_training_data, get_feature_columns,
    plot_accuracy_trend, plot_feature_weights, save_model
)

# --- ç¡®ä¿ç›®å½•å­˜åœ¨ ---
os.makedirs('trained_models', exist_ok=True)
os.makedirs('training_logs', exist_ok=True)


def rolling_train():
    from bayes_opt import BayesianOptimization
    from sklearn.model_selection import cross_val_score
    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
    import numpy as np
    import matplotlib.pyplot as plt
    import pandas as pd
    import warnings
    warnings.filterwarnings('ignore')
    import pickle
    import os

    # ç¡®ä¿æ¨¡å‹å’Œæ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs('trained_models', exist_ok=True)
    os.makedirs('training_logs', exist_ok=True)

    core_df = load_processed_training_data()
    if core_df.empty:
        st.error("æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°å·²å®Œæˆçš„æ¯”èµ›æ•°æ®ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒã€‚")
        return

    date_list = sorted(core_df["betting_cycle_date"].unique())
    feature_cols = get_feature_columns(core_df)

    # -------------------------- ç¬¬ä¸€æ­¥ï¼šè´å¶æ–¯ä¼˜åŒ–è°ƒå‚ --------------------------
    st.subheader("ğŸ” è´å¶æ–¯ä¼˜åŒ–è°ƒå‚ï¼ˆå®æ—¶å±•ç¤ºè¿‡ç¨‹ï¼‰")
    tune_data = core_df.iloc[:int(len(core_df) * 0.8)]
    if len(tune_data) < 5:
        st.warning("è°ƒå‚æ•°æ®ä¸è¶³ï¼ˆ<5æ¡ï¼‰ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ")
        best_params_no = {"max_depth": 4, "eta": 0.2, "alpha": 0.1, "lambda": 0.1, "objective": "multi:softprob",
                          "num_class": 3, "seed": 42}
        best_params_h = best_params_no.copy()
    else:
        X_tune = tune_data[feature_cols].fillna(0)
        y_tune_no = tune_data["no_handicap_result"].values
        y_tune_h = tune_data["handicap_result"].values

        opt_history_no, opt_history_h = [], []

        def objective_no(max_depth, eta, alpha, lambda_, num_round):
            params = {"max_depth": int(max_depth), "eta": eta, "alpha": alpha, "lambda": lambda_,
                      "objective": "multi:softprob", "num_class": 3, "eval_metric": "merror", "seed": 42, "silent": 1}
            dtrain = xgb.DMatrix(X_tune, label=y_tune_no)
            cv_results = xgb.cv(params, dtrain, num_boost_round=int(num_round), nfold=3, early_stopping_rounds=5,
                                verbose_eval=False)
            score = 1 - cv_results["test-merror-mean"].iloc[-1]
            opt_history_no.append({"iter": len(opt_history_no) + 1, "score": score})
            return score

        def objective_h(max_depth, eta, alpha, lambda_, num_round):
            params = {"max_depth": int(max_depth), "eta": eta, "alpha": alpha, "lambda": lambda_,
                      "objective": "multi:softprob", "num_class": 3, "eval_metric": "merror", "seed": 42, "silent": 1}
            dtrain = xgb.DMatrix(X_tune, label=y_tune_h)
            cv_results = xgb.cv(params, dtrain, num_boost_round=int(num_round), nfold=3, early_stopping_rounds=5,
                                verbose_eval=False)
            score = 1 - cv_results["test-merror-mean"].iloc[-1]
            opt_history_h.append({"iter": len(opt_history_h) + 1, "score": score})
            return score

        st.write("ğŸ“Š èƒœå¹³è´Ÿæ¨¡å‹è°ƒå‚ä¸­...")
        optimizer_no = BayesianOptimization(f=objective_no,
                                            pbounds={"max_depth": (2, 6), "eta": (0.05, 0.3), "alpha": (0, 3),
                                                     "lambda_": (0, 3), "num_round": (50, 200)},
                                            random_state=42, verbose=1)
        optimizer_no.maximize(init_points=3, n_iter=10)
        best_params_no = optimizer_no.max["params"]
        best_params_no.update({"max_depth": int(best_params_no["max_depth"]),
                               "num_round": int(best_params_no["num_round"])})
        best_params_no["objective"] = "multi:softprob"
        best_params_no["num_class"] = 3

        st.write("ğŸ“Š è®©çƒèƒœå¹³è´Ÿæ¨¡å‹è°ƒå‚ä¸­...")
        optimizer_h = BayesianOptimization(f=objective_h,
                                           pbounds={"max_depth": (2, 6), "eta": (0.05, 0.3), "alpha": (0, 3),
                                                    "lambda_": (0, 3), "num_round": (50, 200)},
                                           random_state=42, verbose=1)
        optimizer_h.maximize(init_points=3, n_iter=10)
        best_params_h = optimizer_h.max["params"]
        best_params_h.update({"max_depth": int(best_params_h["max_depth"]),
                              "num_round": int(best_params_h["num_round"])})
        best_params_h["objective"] = "multi:softprob"
        best_params_h["num_class"] = 3

        st.success("âœ… è°ƒå‚å®Œæˆï¼æœ€ä¼˜å‚æ•°å¦‚ä¸‹ï¼š")
        col1, col2 = st.columns(2)
        with col1:
            st.write("**èƒœå¹³è´Ÿæ¨¡å‹**")
            for k, v in best_params_no.items():
                st.write(f"- {k}: {v}")
        with col2:
            st.write("**è®©çƒèƒœå¹³è´Ÿæ¨¡å‹**")
            for k, v in best_params_h.items():
                st.write(f"- {k}: {v}")

    # -------------------------- ç¬¬äºŒæ­¥ï¼šåˆå§‹åŒ–è®­ç»ƒç»„ä»¶ --------------------------
    model_cache_no, model_cache_h = [], []
    train_history = pd.DataFrame(columns=["date", "train_days", "no_acc", "h_acc", "no_train_loss", "h_train_loss"])
    feature_weights = pd.DataFrame(columns=["date", "feature_name", "weight"])
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_steps = len(date_list)
    no_label_map = {0: "è´Ÿ", 1: "å¹³", 2: "èƒœ"}
    h_label_map = {0: "è®©è´Ÿ", 1: "è®©å¹³", 2: "è®©èƒœ"}

    def weighted_predict(X, cache, dmatrix=True):
        if len(cache) == 0:
            return np.array([])
        pred_probs_list = []
        for m in cache:
            prob = m.predict(X) if dmatrix else m.predict(xgb.DMatrix(X))
            pred_probs_list.append(prob)
        weights = [0.2, 0.3, 0.5][-len(cache):]
        avg_probs = sum(prob * w for prob, w in zip(pred_probs_list, weights))
        y_pred = avg_probs.argmax(axis=1).astype(int)
        return y_pred

    # -------------------------- ç¬¬ä¸‰æ­¥ï¼šæ»šåŠ¨è®­ç»ƒå¾ªç¯ --------------------------
    for i in range(len(date_list)):
        test_date = date_list[i]
        test_df = core_df[core_df["betting_cycle_date"] == test_date]
        train_dates = date_list[:i] if i > 0 else [test_date]
        train_df = core_df[core_df["betting_cycle_date"].isin(train_dates)]

        st.write(f"**[è¿­ä»£ {i + 1}/{total_steps}] å¤„ç†æ—¥æœŸ: {test_date}**")
        st.write(f"è®­ç»ƒé›†æ ·æœ¬æ•°ï¼š{len(train_df)} | æµ‹è¯•é›†æ ·æœ¬æ•°ï¼š{len(test_df)}")
        if train_df.empty or test_df.empty:
            st.warning("è®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©ºï¼Œè·³è¿‡æœ¬è½®è¿­ä»£ã€‚")
            continue

        X_train = train_df[feature_cols].fillna(0)
        y_train_no = train_df["no_handicap_result"].values
        y_train_h = train_df["handicap_result"].values
        X_test = test_df[feature_cols].fillna(0)
        y_test_no = test_df["no_handicap_result"].values
        y_test_h = test_df["handicap_result"].values

        dtrain_no = xgb.DMatrix(X_train, label=y_train_no)
        dtrain_h = xgb.DMatrix(X_train, label=y_train_h)
        dtest_no = xgb.DMatrix(X_test)
        dtest_h = xgb.DMatrix(X_test)

        params_no = best_params_no.copy()
        params_h = best_params_h.copy()
        params_no.pop("num_round", None)
        params_h.pop("num_round", None)

        model_no = xgb.train(params_no, dtrain_no, num_boost_round=best_params_no["num_round"])
        model_h = xgb.train(params_h, dtrain_h, num_boost_round=best_params_h["num_round"])

        no_train_loss = float(model_no.eval(dtrain_no).split()[1].split(':')[1])
        h_train_loss = float(model_h.eval(dtrain_h).split()[1].split(':')[1])

        model_cache_no.append(model_no)
        model_cache_h.append(model_h)
        if len(model_cache_no) > 3: model_cache_no.pop(0)
        if len(model_cache_h) > 3: model_cache_h.pop(0)

        y_pred_no = weighted_predict(dtest_no, model_cache_no)
        y_pred_h = weighted_predict(dtest_h, model_cache_h)

        # -------------------------- è®¡ç®—æŒ‡æ ‡ --------------------------
        acc_no, acc_h = np.nan, np.nan
        no_cm, no_report, h_cm, h_report = None, None, None, None
        # æ–°å¢ï¼šæå‰åˆå§‹åŒ– target_namesï¼Œé¿å…åç»­å¼•ç”¨é”™è¯¯
        target_names_no, target_names_h = [], []

        if len(y_pred_no) == len(y_test_no) and len(y_pred_no) > 0:
            acc_no = accuracy_score(y_test_no, y_pred_no)
            no_cm = confusion_matrix(y_test_no, y_pred_no)
            existing_classes_no = sorted(list(set(y_test_no) | set(y_pred_no)))
            target_names_no = [no_label_map[cls] for cls in existing_classes_no]
            no_report = classification_report(y_test_no, y_pred_no, labels=existing_classes_no,
                                              target_names=target_names_no, output_dict=True, zero_division=0)
            st.write("èƒœå¹³è´Ÿå‡†ç¡®ç‡ï¼š", acc_no)
        else:
            st.warning("èƒœå¹³è´Ÿæ ·æœ¬æ•°ä¸åŒ¹é…ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡")

        if len(y_pred_h) == len(y_test_h) and len(y_pred_h) > 0:
            acc_h = accuracy_score(y_test_h, y_pred_h)
            h_cm = confusion_matrix(y_test_h, y_pred_h)
            existing_classes_h = sorted(list(set(y_test_h) | set(y_pred_h)))
            target_names_h = [h_label_map[cls] for cls in existing_classes_h]
            h_report = classification_report(y_test_h, y_pred_h, labels=existing_classes_h, target_names=target_names_h,
                                             output_dict=True, zero_division=0)
            st.write("è®©çƒå‡†ç¡®ç‡ï¼š", acc_h)
        else:
            st.warning("è®©çƒèƒœå¹³è´Ÿæ ·æœ¬æ•°ä¸åŒ¹é…ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡")

        # æ›´æ–°è®­ç»ƒå†å²
        new_history_entry = pd.DataFrame({
            "date": [test_date], "train_days": [i + 1],
            "no_acc": [acc_no], "h_acc": [acc_h],
            "no_train_loss": [no_train_loss], "h_train_loss": [h_train_loss]
        })
        train_history = pd.concat([train_history, new_history_entry], ignore_index=True)

        # -------------------------- æå–ç‰¹å¾æƒé‡ --------------------------
        weights_no = pd.Series(model_no.get_score(importance_type='weight'), name='no_weight').fillna(0)
        weights_h = pd.Series(model_h.get_score(importance_type='weight'), name='h_weight').fillna(0)
        combined_weights = pd.concat([weights_no, weights_h], axis=1).fillna(0)
        combined_weights['avg_weight'] = (combined_weights['no_weight'] + combined_weights['h_weight']) / 2
        avg_weights = combined_weights['avg_weight'].to_dict()

        weight_df = pd.DataFrame({
            "date": [test_date] * len(avg_weights),
            "feature_name": list(avg_weights.keys()),
            "weight": list(avg_weights.values())
        })
        feature_weights = pd.concat([feature_weights, weight_df], ignore_index=True)

        # å®æ—¶è¯„ä¼°å±•ç¤º
        progress = (i + 1) / total_steps
        progress_bar.progress(progress)
        status_text.text(f"æ­£åœ¨å¤„ç†ï¼š{test_date}ï¼ˆè¿›åº¦ï¼š{progress:.1%}ï¼‰")
        st.success(f"### æ—¥æœŸ {test_date} è®­ç»ƒç»“æœ")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("èƒœå¹³è´Ÿå‡†ç¡®ç‡", f"{acc_no:.3f}")
        with col2:
            st.metric("è®©çƒå‡†ç¡®ç‡", f"{acc_h:.3f}")
        with col3:
            st.metric("èƒœå¹³è´Ÿè®­ç»ƒæŸå¤±", f"{no_train_loss:.3f}")
        with col4:
            st.metric("è®©çƒè®­ç»ƒæŸå¤±", f"{h_train_loss:.3f}")

        # -------------------------- è¯¦ç»†æŠ¥å‘Š --------------------------
        with st.expander("ğŸ“‹ èƒœå¹³è´Ÿè¯¦ç»†æŠ¥å‘Š", expanded=False):
            if no_cm is not None:
                cm_classes = sorted(list(set(y_test_no)))
                cm_index = [no_label_map[cls] for cls in cm_classes]
                st.dataframe(pd.DataFrame(no_cm, index=cm_index, columns=cm_index))
                st.text("æ··æ·†çŸ©é˜µ")

            # **æ ¸å¿ƒä¿®å¤**ï¼šå°† report_df çš„ç”Ÿæˆå’Œå±•ç¤ºé€»è¾‘å®Œå…¨æ”¾åœ¨ if no_report is not None: å†…éƒ¨
            if no_report is not None and len(target_names_no) > 0:
                report_df = pd.DataFrame({
                    "ç²¾ç¡®ç‡": [no_report[label]["precision"] for label in target_names_no],
                    "å¬å›ç‡": [no_report[label]["recall"] for label in target_names_no],
                    "F1å€¼": [no_report[label]["f1-score"] for label in target_names_no]
                }, index=target_names_no)
                st.dataframe(report_df.round(3))
                st.text("åˆ†ç±»æŒ‡æ ‡")
            else:
                st.info("æ— æœ‰æ•ˆåˆ†ç±»æŠ¥å‘Šæ•°æ®")

        with st.expander("ğŸ“‹ è®©çƒèƒœå¹³è´Ÿè¯¦ç»†æŠ¥å‘Š", expanded=False):
            if h_cm is not None:
                cm_classes = sorted(list(set(y_test_h)))
                cm_index = [h_label_map[cls] for cls in cm_classes]
                st.dataframe(pd.DataFrame(h_cm, index=cm_index, columns=cm_index))
                st.text("æ··æ·†çŸ©é˜µ")

            # **æ ¸å¿ƒä¿®å¤**ï¼šåŒç†ï¼Œè®©çƒèƒœå¹³è´Ÿéƒ¨åˆ†ä¹ŸåšåŒæ ·å¤„ç†
            if h_report is not None and len(target_names_h) > 0:
                report_df = pd.DataFrame({
                    "ç²¾ç¡®ç‡": [h_report[label]["precision"] for label in target_names_h],
                    "å¬å›ç‡": [h_report[label]["recall"] for label in target_names_h],
                    "F1å€¼": [h_report[label]["f1-score"] for label in target_names_h]
                }, index=target_names_h)
                st.dataframe(report_df.round(3))
                st.text("åˆ†ç±»æŒ‡æ ‡")
            else:
                st.info("æ— æœ‰æ•ˆåˆ†ç±»æŠ¥å‘Šæ•°æ®")

        st.divider()

    # -------------------------- è®­ç»ƒå®Œæˆåå¤„ç† --------------------------
    progress_bar.empty()
    status_text.empty()

    if 'model_no' in locals() and 'model_h' in locals():
        model_no.save_model('trained_models/model_no_latest.json')
        model_h.save_model('trained_models/model_h_latest.json')
        pickle.dump(model_cache_no, open('trained_models/model_cache_no.pkl', 'wb'))
        pickle.dump(model_cache_h, open('trained_models/model_cache_h.pkl', 'wb'))

        log_filename = f"training_logs/æ»šåŠ¨è®­ç»ƒæ—¥å¿—_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
        if not train_history.empty:
            train_history.to_csv(log_filename, index=False, encoding="utf-8-sig")

        st.session_state['train_history'] = train_history
        st.session_state['feature_weights'] = feature_weights
        st.info(f"ğŸ‰ æ‰€æœ‰è®­ç»ƒå®Œæˆï¼\n- æ¨¡å‹ä¿å­˜ï¼štrained_models/\n- æ—¥å¿—ï¼š{log_filename}")
    else:
        st.error("æ¨¡å‹æœªæˆåŠŸåˆå§‹åŒ–ï¼Œæ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§ï¼")


def main():
    st.set_page_config(page_title="æ¨¡å‹è®­ç»ƒ - è¶³çƒæ¯”èµ›é¢„æµ‹ç³»ç»Ÿ", layout="wide")
    st.title("âš½ æ¨¡å‹è®­ç»ƒï¼ˆå•å¤©è®­ç»ƒç‰ˆï¼‰")

    # åˆå§‹åŒ–Session State
    if 'train_history' not in st.session_state:
        st.session_state['train_history'] = pd.DataFrame()
    if 'feature_weights' not in st.session_state:
        st.session_state['feature_weights'] = pd.DataFrame()

    # è®­ç»ƒæ§åˆ¶åŒº
    st.header("ğŸš€ å¼€å§‹è®­ç»ƒ")
    st.write("""
    è®­ç»ƒè¯´æ˜ï¼š
    1. è‡ªåŠ¨åŠ è½½æ•°æ®åº“ä¸­æ‰€æœ‰å·²å®Œæˆçš„æ¯”èµ›æ•°æ®ï¼ˆå«ç›˜å£ï¼‰
    2. æ”¯æŒå•å¤©æ•°æ®è®­ç»ƒï¼ˆè®­ç»ƒé›†=æµ‹è¯•é›†ï¼‰
    3. èƒœå¹³è´Ÿ + è®©çƒèƒœå¹³è´Ÿ åŒæ¨¡å‹å¹¶è¡Œè®­ç»ƒ
    4. é‡‡ç”¨3æ¨¡å‹åŠ æƒå¹³æ»‘é¢„æµ‹ï¼Œè‡ªåŠ¨å­¦ä¹ åŒå¹³ï¼ˆdpï¼‰ç­‰ç‰¹å¾çš„æƒé‡
    5. å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œå‡†ç¡®ç‡
    """)

    if st.button("å¯åŠ¨è®­ç»ƒ", type="primary", use_container_width=True):
        with st.spinner("è®­ç»ƒä¸­... è¯·è€å¿ƒç­‰å¾…ï¼ˆæ—¶é—´å–å†³äºæ•°æ®é‡ï¼‰"):
            rolling_train()

    # è®­ç»ƒç»“æœå¯è§†åŒ–åŒº
    st.header("ğŸ“ˆ è®­ç»ƒç»“æœå¯è§†åŒ–")
    if st.session_state['train_history'].empty:
        st.info("è¯·å…ˆå¯åŠ¨è®­ç»ƒä»¥æŸ¥çœ‹å¯è§†åŒ–ç»“æœ")
    else:
        tab1, tab2 = st.tabs(["å‡†ç¡®ç‡è¶‹åŠ¿", "ç‰¹å¾æƒé‡åˆ†æ"])
        with tab1:
            fig = plot_accuracy_trend(st.session_state['train_history'])
            if fig:
                st.pyplot(fig)
                # æ˜¾ç¤ºè¯¦ç»†è®­ç»ƒæ—¥å¿—
                st.subheader("è®­ç»ƒæ—¥å¿—è¯¦æƒ…")
                st.dataframe(st.session_state['train_history'].round(3), use_container_width=True)
        with tab2:
            weights_df = st.session_state['feature_weights']
            if not weights_df.empty:
                # æ—¥æœŸé€‰æ‹©å™¨
                weights_df['date'] = pd.to_datetime(weights_df['date'])
                min_date = weights_df["date"].min().date()
                max_date = weights_df["date"].max().date()
                selected_date = st.date_input("é€‰æ‹©æŸ¥çœ‹æ—¥æœŸ", max_date, min_value=min_date, max_value=max_date)

                # TopNé€‰æ‹©å™¨
                top_n = st.slider("æ˜¾ç¤ºTop Né¢„æµ‹è€…", min_value=5, max_value=30, value=10)

                # ç»˜åˆ¶æƒé‡å›¾
                fig = plot_feature_weights(weights_df, selected_date, top_n)
                if fig:
                    st.pyplot(fig)

                    # æ˜¾ç¤ºæƒé‡è¯¦æƒ…è¡¨ï¼ˆå¯è§‚å¯ŸåŒå¹³ç‰¹å¾çš„æƒé‡ï¼‰
                    st.subheader("ç‰¹å¾æƒé‡è¯¦æƒ…")
                    daily_weights = weights_df[weights_df["date"].dt.date == selected_date].sort_values('weight',
                                                                                                        ascending=False)
                    st.dataframe(daily_weights[['feature_name', 'weight']].round(4), use_container_width=True)


if __name__ == "__main__":
    main()